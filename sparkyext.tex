\documentclass[11pt,a4paper]{article}
\usepackage[top=30mm, bottom=30mm, left=30mm, right=30mm]{geometry}
\usepackage{microtype} % makes things look nicer ??
\usepackage{times} % ???
\usepackage{graphicx} % for pictures
\usepackage{hyperref} % for internal links
\DeclareGraphicsExtensions{.jpg, .png}
\usepackage[T1]{fontenc} % see http://tex.stackexchange.com/questions/664/



\begin{document}

\author{Matthew Fenwick}
\title{Sparky reproducibility extension for NMR data analysis}
\maketitle

\begin{abstract}
Sparky \cite{sparky} 
is a popular program for analysis of NMR data, including peak picking,
GSS construction, and GSS assignment.  It is designed for flexibility in that
it includes a Python interpreter and an API accessible from Python programs
which allows interaction with and manipulation of its data model.  This makes
it possible to write extensions which automatically perform complex
computational tasks.

I have implemented an extension which facilitates reproducible data analysis
by extending the Sparky data model such that additional data can be easily
collected during the analysis process.  This additional data is sufficient
to render the process reproducible.

This document discusses the concepts of the extended data model, as well as
how to use the extension for reproducible analysis.
\end{abstract}

\tableofcontents
\listoftables
\listoffigures


\section{Sparky notes}
Once the project is loaded, use the "re" shortcut to bring up the 
reproducibility menu.  "js", "jc", and "jo" -- save project, close project,
and open project -- are also very useful shortcuts.


\section{Concepts}

No automated algorithm is perfect in the NMR process.  Automated peak picking,
GSS construction, and GSS-residue assignment needs manual validation and
correction.  The main goal of this extension is to support these manual
modifications in such a way that the modifications are captured in full so
as to be recapitulable at a later time.

The process of manual analysis is composed of a series of discrete steps.
At each step, a deductive rule is applied to the data set, producing a
modified new data set.  Thus, for each rule, knowing the context is important:
it allows one to determine how appropriate the application of a specific rule
is, as well as what the results should be, and to determine whether the 
results are consistent with expectations.

\subsection{GSS and resonance}
Sparky does not natively distinguish between a GSS (generic spin system) and
a residue, nor between a resonance and an atom.

A resonance is the NMR-visible signal due to an atom (or of a group of
atoms if they are not distinguishable in NMR experiments).  An atom generally
resonates at the same frequency across all experiments; a resonance is used
to capture this relationship.  Thus, two signals at the same frequency
may be the same resonance (although it is also possible that two resonances
coincidentally appear at the same frequency -- but this is often resolved
through couplings to other, covalently-bound resonances).  Ignoring overlap,
each cross-section of a peak corresponds to one resonance.

A GSS is a group of covalently bound resonances, which interact through 
scalar couplings.  In a through-bond experiment, by definition, all the
resonances assigned to a single peak belong to the same GSS.  Multiple peaks
are determined to be in the same GSS by the overlap of resonances (resonances
with identical or nearly identical chemical shifts).  GSSs are eventually
assigned to residues in the primary sequence of the protein, which determines
the chemical shift assignments.

These have been implemented in the extension, based on the CCPN model \cite{ccpn}.

\subsection{Extraneous data}
In standard analysis, false positive peaks (picked as true peaks initially,
but later determined to be noise or artifactual) and false positive spin 
systems (not assigned to any residue) are typically deleted and/or ignored.
In this extension, \textbf{data is never deleted}.  Such results are kept,
since they have valuable information content, even if they are not used for
the immediate purpose of the analysis process (be it structure or dynamics
determination).  These results are kept by, instead of deleting them, 
explicitly marking them as not of interest, and placed in a different
category.

\subsection{Snapshots}
Snapshots of intermediate states during analysis are used to enable rehashing
of the deductive process.  In general, by capturing a snapshot of the data set
each time a deductive rule is applied, the context of each manual modification
is captured.

An additional benefit of capturing snapshots is that they allow one to go 
backward in time.  This can be useful for understanding what happened and
why, but it is also useful for fixing mistakes and accidents -- and this is
quite important, because Sparky doesn't really have the capability to undo
changes.  So if something accidentally gets changed: 1) you might not even
notice, and 2) you probably won't be able to restore it easily.  Capturing
snapshots makes solving both of these problems trivial.

\subsection{Deductive reasoning}
Capturing the deductive rules applied during the process of manual assignment
provides semantic information about what is being done and why.  This makes it
far more meaningful to examine the sequence of snapshots of an analysis
process and determine the context.


\section{Prerequisites}
\begin{itemize}
  \item Sparky
    (at \url{http://pine.nmrfam.wisc.edu/download_packages.html})
  \item reproducibility extension
    (at \url{https://github.com/mattfenwick/SparkyExtensions/tree/master/Contents/Resources/python/sparky})
  \item git
    (at \url{http://git-scm.com/downloads})
\end{itemize}


\section{Setup}
Create an empty git repository.  Move to the directory of your choice, and
run:
\begin{verbatim}
$ git init
$ mkdir Projects/
$ mkdir Save/
$ mkdir Data/
\end{verbatim} 
to create and initialize the repository.  
Save all spectra files in the "Data/" directory.
When in Sparky, save the project in the "Projects/" directory.
The Sparky .save files will automatically be written into the "Save/"
directory.

\subsection{Capturing a snapshot}
\begin{itemize}
  \item save the project ("js")
  \item type in the appropriate deductive reason in the "deductive reason used"
    text box
  \item click the "make snapshot" button
\end{itemize}
This will use git to create a new snapshot.  At any time, the contents of
the git repo can be examined using the terminal and the file browser.  Git
supports many features for examining and manipulating history.  These may
all be accessed from the terminal.


\section{Peak picking and signal/noise/artifact identification}
Use standard Sparky facilities to peak pick your NHSQC spectrum.

Some of the peaks Sparky found will turn out to be noise or artifact peaks.
\textbf{Do not delete peaks, ever, for any reason!}  Instead,
when peaks are identified as such, select them and press the "Set selected 
peaks to noise" or "Set selected peaks to artifact" button, as necessary.
Peaks must not be assigned when setting them to noise or artifact.

Sparky will not find all true peaks.  When these are identified, simply
pick the peak manually.

Overlapped peaks are also a problem.  They may cause too few peaks to be 
picked, or peaks to be picked in a slightly wrong position.  If these errors
can be rectified manually, simply add peaks and move others as necessary.

Either a restricted peak pick (using NHSQC peaks) or a standard peak pick
of the full dimensions should be used to peak pick all other N-H-rooted
spectra (such as the HNCO, HNCACB, CCONH-Tocsy, etc.).


\section{GSS initialization}
It is convenient to create one GSS for each NHSQC peak that is (or may be)
a signal peak.  \textit{This functionality is currently available through
the Python shell.}  Use the keyboard shortcut "py" to bring up the shell.
Then, select the NHSQC peaks which will be used as GSS roots.  
All signal peaks can be selected using the "select signal peaks" button.
In the shell, type in:
\begin{verbatim}
import sparky.r_model as mod
mod.create_group_for_peak()
\end{verbatim}

When an NHSQC peak is used to initialize a GSS, the GSS will start off
with two resonances: one for the H, and one for the N.


\section{GSS construction}
Use the "Automatically group peaks into GSS" button, setting the parameters
appropriately.

The way that GSS construction works is that for each peak in the "from"
spectrum, all peaks in the "to" spectrum within the tolerances will be
assigned to the same GSS as the "from" peak.  Peaks in the "to" spectrum that
match 0 "from" peaks will not be assigned to any GSS; those that match more
than 1 peak will also not be assigned, but a warning will be generated in
the shell, allowing manual resolution.

Matching requires that some subset of the spectral dimensions match.  Using
an NHSQC and an HNCACB, the H and the N dimensions match.  The resonance
assignments of the peak dimensions will be carried over for matching dimensions,
and new resonances will be created for the C dimension.

Only selected peaks in the "from" spectrum will be used; the "select signal 
peaks" button is again useful for performing GSS construction across the
entire spectrum at once.


\section{Peak dimension to resonance assignment}
Peak dimension to resonance assignment can fail in two cases.

First, when the chemical shifts between the peak dimensions don't match
within the tolerances, multiple resonances are created.  These can be merged
using the built-in Sparky assignment tools by changing the assignment of one
peak dimension to match the other.

Second, in the case of overlap, a single resonance is created when there
should actually be multiple resonances.  This can also be resolved using
the built-in Sparky assignment tools, by simply changing the assignment of
one peak dimention to a fresh resonance id.


\section{Changing peak-GSS assignments}
There are two major cases for moving a peak from one GSS to another.

First, for GSS types such as Q and N sidechains, where there are multiple
peaks in the NHSQC (because of the two protons).  Simply select the appropriate
peaks, choose a GSS id (typically the lowest of the GSS ids of the selected
peaks, just for convenience and consistency) and press the "set groups of
selected peaks" button.

Second, for correcting mistakes.  Select the incorrectly assigned peaks,
type in the desired GSS id, and press the "set groups of selected peaks" button.


\section{Resonance typing}
The types of resonances are assigned using BMRB statistics, GSS typing, 
peak characteristics,
and the pulse sequences of the spectra in which they appear.  For some spectra,
such as the NHSQC, there are relatively few choices: for backbone GSSs,
the resonance types are always amide-H and amide-N.  However, other spectra
have more choices: for the HNCACB, resonances in backbone GSSs in the C
dimension can be CA, CA(i-1), CB, or CB(i-1).

There are two ways to assign resonance types.  First, a peak may be assigned
a peaktype.  A peaktype is a set of resonance types visible in a pulse sequence
-- thus, all the resonance types of a single peak are assigned simultaneously.
This can be done using "assign peaktype" drop-down menu.

The second way is to assign resonance types individually.  This can be done 
using the "set resonance assignment" dialog.

Ambiguous resonance typings are also supported.  Common examples include
CA/CA(i-1), HA2/HA3 (Glycine), HB2/HB3 (many amino acids), and QB (Alanine).


\section{GSS typing}
GSSs are assigned types based on BMRB statistics, the presence or absence of
characteristics resonance types, and possibly also based on the assignments 
of linked GSSs.

GSS types for H-N-rooted GSSs include backbone types for each of the 20 
standard amino acids, as well as sidechain types for Q, N, R, W, and K.

GSS typing is accomplished using the "assign amino acid type" dialog.


\section{Sequential GSS assignment}
Sequentiall GSS assignments are identified based on overlapping compatible
resonances between GSSs: for example, a GSS with a CA at 58.32 PPM and a CB
at 30.27 PPM, and a second GSS with a CA(i-1) at 58.21 and a CB(i-1) at 30.41:
these GSSs have overlapping compatible resonances and can be sequentially
assigned.

It is not necessary that resonance types are unambiguously assigned before
doing sequential GSS assignments: if it is unclear whether a resonance is a
CA or CA(i-1), this may be assigned simultaneously as the sequential assignment
is made, if it is consistent with the overlap from the other GSS.

Additionally, sequential GSS assignment can lead to the picking of additional
peaks, or the resolution of GSS overlap, if such picking and/or resolution
leads to consistent and compatible overlap with another GSS.

Sequential GSS assignment is accomplished using the "set sequential group
assignment" dialog.


\section{GSS-residue assignment}
GSSs are assigned to residues on the basis of GSS typing, sequential GSS
assignments, and the primary sequence.

This can be done using the "set group-residue assignment" dialog.


\section{Gotchas}
Since Sparky's data model does not natively understand GSSs and resonances,
there are some limitations associated with the enhanced data model provided
by this extension.  It is possible to assign peaks without using the 
reproducibility menu, but if care is not taken when doing so, the peak
assignments may be incompatible with the extension.


% acknowledgements

% not sure what the difference is between `unsrt` and `ieeetr`
% also see `natbib` for another possible alternative
%\bibliographystyle{unsrt}
\bibliographystyle{ieeetr} % supposed to use `natbib` and format them differently
\bibliography{sparkyext}

\end{document}

